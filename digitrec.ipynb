{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enmwmak/Speech-Recognition/blob/main/digitrec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fszgXmA8MZY"
      },
      "source": [
        "**EIE558 Speech Recognition Lab (Part 1): Spoken-Digit Recognition**\n",
        "\n",
        "In this lab, you will train and evaluate a CNN model that comprises several 1-D CNN layers for spoken digit recognition. By default, the input to the CNN is an MFCC matrix of size *C* x *T*, where *C* is the number MFCC coefficients per frame and *T* is the number of frames. \n",
        "\n",
        "Two pooling methods are available for converting frame-based features to utterance-based features. They are adaptive average pooling and statistics pooling. The former uses PyTorch's AdaptiveAvgPooling2d() to average the last convolutional layer's activation across the frame axis. The latter concatenates the mean and the standard deviation of the activations across frames, which is commonly used in the x-vector network. If no pooling method is used, the number of frames for each utterance should be the same so that the number of nodes after flattening is identical for all utterances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186SdUa78s9A"
      },
      "source": [
        "<font color=\"green\">*Step 1: Prepare environment*<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzQNackhq703",
        "outputId": "a9601872-bf86-4ca8-a565-286a13caef32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Learning/EIE558/asr\n"
          ]
        }
      ],
      "source": [
        "# If you use Colab, run this cell to mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/MyDrive/Learning/EIE558/asr\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/asr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4Z3rZq8aY3n"
      },
      "outputs": [],
      "source": [
        "# If you use Anaconda environment, you must start the anaconda env and launch Jupyter notebook from that environment. For example:\n",
        "$ conda activate myenv\n",
        "$ juypter notebook\n",
        "# You will see Jupyter on your browser and you are ready to go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxe4pDMzaY3n",
        "outputId": "924d920c-2ffa-4c5e-dfa8-d4e245e41b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "# Check the version of PyTorch\n",
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41E_3gSuyScL"
      },
      "source": [
        "<font color=\"green\">*Step 2: Download programs and data. If the 'python-asr' directory exists and is empty, you may delete the 'python-asr' directory and run this step again.*<font> <font color=\"red\">*In case the website http://bioinfo.eie.polyu.edu.hk is too slow or busy, you may find the files [here](https://polyuit-my.sharepoint.com/:f:/g/personal/enmwmak_polyu_edu_hk/EpX3v5ykT_VLoiBa8jrpJ70B52X4XbEPQcyrDnLAquEcIA?e=d5Xjrv)<font>*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh-jUQpD7gde",
        "outputId": "aca10dc6-2d3c-4112-a7a4-5fa42b5dd09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/enmwmak/Documents/Doc/Teaching/EIE558/Lab/Lab-materials/asr\n",
            "Directory python-asr does not exist. Downloading python-asr.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-03-20 12:21:07--  http://bioinfo.eie.polyu.edu.hk/download/EIE558/asr/python-asr.tgz\n",
            "Resolving bioinfo.eie.polyu.edu.hk (bioinfo.eie.polyu.edu.hk)... 158.132.151.227\n",
            "Connecting to bioinfo.eie.polyu.edu.hk (bioinfo.eie.polyu.edu.hk)|158.132.151.227|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 853815 (834K)\n",
            "Saving to: ‘python-asr.tgz’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  5% 1.25M 1s\n",
            "    50K .......... .......... .......... .......... .......... 11% 2.38M 0s\n",
            "   100K .......... .......... .......... .......... .......... 17% 9.12M 0s\n",
            "   150K .......... .......... .......... .......... .......... 23% 3.93M 0s\n",
            "   200K .......... .......... .......... .......... .......... 29% 3.39M 0s\n",
            "   250K .......... .......... .......... .......... .......... 35% 5.67M 0s\n",
            "   300K .......... .......... .......... .......... .......... 41% 3.86M 0s\n",
            "   350K .......... .......... .......... .......... .......... 47% 6.25M 0s\n",
            "   400K .......... .......... .......... .......... .......... 53% 5.80M 0s\n",
            "   450K .......... .......... .......... .......... .......... 59% 4.41M 0s\n",
            "   500K .......... .......... .......... .......... .......... 65% 5.09M 0s\n",
            "   550K .......... .......... .......... .......... .......... 71% 4.91M 0s\n",
            "   600K .......... .......... .......... .......... .......... 77% 4.91M 0s\n",
            "   650K .......... .......... .......... .......... .......... 83% 4.37M 0s\n",
            "   700K .......... .......... .......... .......... .......... 89% 1.92M 0s\n",
            "   750K .......... .......... .......... .......... .......... 95%  268M 0s\n",
            "   800K .......... .......... .......... ...                  100%  275M=0.2s\n",
            "\n",
            "2022-03-20 12:21:07 (3.94 MB/s) - ‘python-asr.tgz’ saved [853815/853815]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pwd\n",
        "dir=\"python-asr\"\n",
        "if [ ! -d \"$dir\" ]; then\n",
        "  echo \"Directory $dir does not exist. Downloading ${dir}.tgz\"\n",
        "  wget http://bioinfo.eie.polyu.edu.hk/download/EIE558/asr/${dir}.tgz;\n",
        "  tar zxf ${dir}.tgz;\n",
        "  rm -f ${dir}.tgz*;\n",
        "else\n",
        "  echo \"Directory $dir already exist\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktE1Vm9AaY3p",
        "outputId": "20ecf125-5935-4c07-f7cc-446136e1418e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/enmwmak/Documents/Doc/Teaching/EIE558/Lab/Lab-materials/asr/python-asr\n",
            "\u001b[34m__pycache__\u001b[m\u001b[m  \u001b[31mdigitrec.py\u001b[m\u001b[m  \u001b[34mmodels\u001b[m\u001b[m       \u001b[31msphrec.py\u001b[m\u001b[m\r\n",
            "\u001b[34mdata\u001b[m\u001b[m         \u001b[31mmodel.py\u001b[m\u001b[m     \u001b[31mresnet_1d.py\u001b[m\u001b[m\r\n"
          ]
        }
      ],
      "source": [
        "# If you run this notebook file on your own computer, run this cell\n",
        "%cd python-asr\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzoJNd6PmKt8",
        "outputId": "adfafb5a-b0a9-49de-934f-4474da211166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Learning/EIE558/asr/python-asr\n",
            "data  digitrec.py  model.py  models  __pycache__  resnet_1d.py\tsphrec.py\n"
          ]
        }
      ],
      "source": [
        "# If you run this notebook file on Colab, run this cell\n",
        "%cd /content/drive/MyDrive/Learning/EIE558/asr/python-asr/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUFwZIc-aY3r"
      },
      "source": [
        "<font color=\"green\">*Download datasets (532 MBytes). If the 'data' directory exists and is empty, \n",
        "you may delete the 'data' directory and run this step again.*<font> <font color=\"red\">*In case the website http://bioinfo.eie.polyu.edu.hk is too slow or busy, you may find the files [here](https://polyuit-my.sharepoint.com/:f:/g/personal/enmwmak_polyu_edu_hk/EpX3v5ykT_VLoiBa8jrpJ70B52X4XbEPQcyrDnLAquEcIA?e=d5Xjrv) This step will take a while.<font>*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-ToOSCe6zej"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "dir=\"data\" \n",
        "if [ ! -d $dir ]; then\n",
        "  echo \"Directory $dir does not exist. Downloading ${dir}.zip\"\n",
        "  wget http://bioinfo.eie.polyu.edu.hk/download/EIE558/asr/${dir}.zip;\n",
        "  unzip -o ${dir}.zip;\n",
        "  rm -f ${dir}.zip*;\n",
        "else\n",
        "  echo \"Directory $dir already exist\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub383ypr9D5n"
      },
      "source": [
        "<font color=\"green\">*Step 3: Train a CNN model. It may take several hours to train a model if you use all of the training data in the list file \"data/digits/train.lst\". You may want to use the pre-trained models in the folder \"models/\" if you want to obtain test accuracy only. Read the file \"digitrec.py\" and \"model.py\" to see how to implement a CNN for spoken digit recognition. If you want to train your own models, you may modify the file \"digitrec.py such that \"data/digits/train.lst\" is replaced by \"data/digits/short_train.lst\" and \"data/digits/test.lst\" is replaced by data/digits/short_test.lst\". With these modifications, it will take about 30 minutes to train a network. But the accuracy is lower.*</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3WpCSDnaY3t",
        "outputId": "d7475b57-ffbc-4e85-d23e-8558261e05b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Learning/EIE558/asr/python-asr\n"
          ]
        }
      ],
      "source": [
        "# Make sure that you are still under the folder 'python-asr'\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkf5va9trFc_",
        "outputId": "78f13099-b871-4537-bf68-b9eea4f2753f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch  0\n",
            "100% 32/32 [01:39<00:00,  3.10s/it]\n",
            "Last lr:  0.00027089460458501675  Train_loss:  2.3004677295684814  Val_loss:  2.30424165725708  Accuracy: 7.60%\n",
            "Epoch  1\n",
            "100% 32/32 [01:08<00:00,  2.15s/it]\n",
            "Last lr:  0.0007554032818386438  Train_loss:  2.2868430614471436  Val_loss:  2.2667288780212402  Accuracy: 16.90%\n",
            "Epoch  2\n",
            "100% 32/32 [01:08<00:00,  2.16s/it]\n",
            "Last lr:  0.001  Train_loss:  2.200319528579712  Val_loss:  2.1158347129821777  Accuracy: 33.97%\n",
            "Epoch  3\n",
            "100% 32/32 [01:09<00:00,  2.16s/it]\n",
            "Last lr:  0.0009504846320134736  Train_loss:  2.0882744789123535  Val_loss:  2.013812303543091  Accuracy: 45.52%\n",
            "Epoch  4\n",
            "100% 32/32 [01:09<00:00,  2.17s/it]\n",
            "Last lr:  0.000811745653949763  Train_loss:  2.052488327026367  Val_loss:  1.998216152191162  Accuracy: 47.09%\n",
            "Epoch  5\n",
            "100% 32/32 [01:09<00:00,  2.17s/it]\n",
            "Last lr:  0.0006112620219362892  Train_loss:  1.9934080839157104  Val_loss:  1.919144868850708  Accuracy: 56.04%\n",
            "Epoch  6\n",
            "100% 32/32 [01:08<00:00,  2.14s/it]\n",
            "Last lr:  0.00038874197806371076  Train_loss:  1.9191646575927734  Val_loss:  1.9006667137145996  Accuracy: 57.99%\n",
            "Epoch  7\n",
            "100% 32/32 [01:09<00:00,  2.16s/it]\n",
            "Last lr:  0.00018825834605023698  Train_loss:  1.889436960220337  Val_loss:  1.8761712312698364  Accuracy: 60.23%\n",
            "Epoch  8\n",
            "100% 32/32 [01:09<00:00,  2.17s/it]\n",
            "Last lr:  4.9519367986526286e-05  Train_loss:  1.8612477779388428  Val_loss:  1.8628575801849365  Accuracy: 61.84%\n",
            "Epoch  9\n",
            "100% 32/32 [01:09<00:00,  2.17s/it]\n",
            "Last lr:  4e-09  Train_loss:  1.852123737335205  Val_loss:  1.863848090171814  Accuracy: 61.21%\n"
          ]
        }
      ],
      "source": [
        "# Create reduced training and test set to reduce training and test time\n",
        "!more data/digits/train.lst | sed -n '1,2000p' > data/digits/short_train.lst\n",
        "!more data/digits/test.lst | sed -n '1,500p' > data/digits/short_test.lst\n",
        "!mkdir -p models/mymodels\n",
        "!python3 digitrec.py --pool_method stats --model_file models/mymodels/spokendigit_cnn_stats.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4_dg4YTBuFk"
      },
      "source": [
        "<font color=\"green\">*Step 4: Load the trained model (or the pre-trained model) and evaluate it*</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKLgd6c2SmZy"
      },
      "outputs": [],
      "source": [
        "# Define the prediction function, using a DataLoader object that comprises \n",
        "# the test data as input\n",
        "from digitrec import get_default_device\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_dl(model, dl):\n",
        "    device = get_default_device()\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_probs = []\n",
        "    batch_targ = []\n",
        "    for xb, yb in dl:\n",
        "        xb = xb.float().to(device)\n",
        "        yb = yb.float().to(device)\n",
        "        probs = model(xb)\n",
        "        batch_probs.append(probs.cpu().detach())\n",
        "        batch_targ.append(yb.cpu().detach())\n",
        "    batch_probs = torch.cat(batch_probs)\n",
        "    batch_targ = torch.cat(batch_targ)\n",
        "    return [list(values).index(max(values)) for values in batch_probs], batch_targ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdsBM4z3B64-",
        "outputId": "f36ff01d-2126-4b3d-fb67-0cef290f7977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load the trained model\n",
        "from digitrec import get_default_device\n",
        "from model import CNNModel\n",
        "device = get_default_device()\n",
        "model = CNNModel(pool_method='stats').to(device)\n",
        "model.load_state_dict(torch.load('models/mymodels/spokendigit_cnn_stats.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_y7KtoGpPLU",
        "outputId": "64683cc8-9096-42fe-e86b-796af28d53bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  1.863848090171814 \n",
            "Accuracy:  0.6120793223381042\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the loaded model\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from digitrec import SpeechDataset, evaluate\n",
        "test_set = SpeechDataset(filelist='data/digits/short_test.lst', rootdir='data/digits', n_mfcc=20)\n",
        "test_dl = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
        "r = evaluate(model, test_dl)\n",
        "yp, yt = predict_dl(model, test_dl)\n",
        "print(\"Loss: \", r['loss'], \"\\nAccuracy: \", r['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG5WjvpDNiPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89889525-923a-4095-903e-24eb2db8e10b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Load the pre-trained model that uses statistics pooling in its embedding layer.\n",
        "from digitrec import get_default_device\n",
        "from model import CNNModel\n",
        "device = get_default_device()\n",
        "model = CNNModel(pool_method='stats').to(device)\n",
        "model.load_state_dict(torch.load('models/spokendigit_cnn_stats.pth', \n",
        "                                 map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFvt-DWuN9YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e1fb0d-6a3f-48e7-cae7-7af9f28638fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  1.5558969974517822 \n",
            "Accuracy:  0.900240421295166\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the loaded model\n",
        "r = evaluate(model, test_dl)\n",
        "yp, yt = predict_dl(model, test_dl)\n",
        "print(\"Loss: \", r['loss'], \"\\nAccuracy: \", r['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-D8NrEwaY3x",
        "outputId": "ed0afb46-3316-4006-9f28-076cf2f2f858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Load the pre-trained model that uses adaptive average pooling in its embedding layer.\n",
        "model = CNNModel(pool_method='adapt').to(device)\n",
        "model.load_state_dict(torch.load('models/spokendigit_cnn_adapt.pth', \n",
        "                                 map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nbYePBzaY3y",
        "outputId": "dab36801-1b5e-4237-e4b0-4bc1eae7e868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  1.598436951637268 \n",
            "Accuracy:  0.8578726053237915\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the loaded model\n",
        "r = evaluate(model, test_dl)\n",
        "yp, yt = predict_dl(model, test_dl)\n",
        "print(\"Loss: \", r['loss'], \"\\nAccuracy: \", r['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNZab9naaY3y",
        "outputId": "0e881438-c0fb-4d95-e132-217c687e39b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Load the pre-trained model that use flattening in its embedding layer.\n",
        "model = CNNModel(pool_method='none').to(device)\n",
        "model.load_state_dict(torch.load('models/spokendigit_cnn_none.pth', \n",
        "                                 map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPysLDupaY3z",
        "outputId": "429d6c7e-8755-4174-9f5b-7af8eaca0441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  1.5697848796844482 \n",
            "Accuracy:  0.8850660920143127\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the loaded model\n",
        "r = evaluate(model, test_dl)\n",
        "yp, yt = predict_dl(model, test_dl)\n",
        "print(\"Loss: \", r['loss'], \"\\nAccuracy: \", r['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ojcll2YaY3z"
      },
      "source": [
        "<font color=\"blue\">*Explain the performance difference between (1) CNN with statistics pooling, (2) CNN with average pooling, and (3) CNN with flattening*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nudpBj4Zkemr"
      },
      "source": [
        "<font color=\"green\">*Step 5: Varying the kernel size. Increase the kernel size in \"model.py\" to 7 (or even larger) and repeat Step 4. Record the test loss and accuracy. Reduce the kernel size to 1 and observe the results. Can the CNN still capture the temporal characteristics in the MFCCs when kernel_size=1? Explain your answer.*</font> <font color=\"red\">*If the model remains unchanged even after you have saved the file \"model.py\", you may reset the runtime by selecting \"Runtime\", followed by \"Reset runtime\".*</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNudrUfu49vW"
      },
      "source": [
        "<font color=\"green\">*Step 6: Reduce the depth of the network so that the conv2, conv3, and conv4 in \"model.py\" are removed. After the change, the network only have one convolutional layer. Observe the performance of the network. Note that large and deep networks may not necessary produce better results, especially when the amount of training data is limited.*</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDjDGSNEOAPh",
        "outputId": "39d92b23-c97a-4144-d6e0-b3a59050bf9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNNModel(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv1d(20, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=(128, 1))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
            "    (3): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from model import CNNModel\n",
        "model = CNNModel(pool_method='adapt')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLb4RLx9aY31"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1HPmkNS36wEv",
        "Io-WhKnHUh6P"
      ],
      "name": "digitrec.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "py39"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}